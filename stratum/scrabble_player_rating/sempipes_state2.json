{
    "generated_code": [
        "\n# (avg_time_per_turn: Average time spent on each turn)\n# Usefulness: Captures player pacing/strategy, can indicate playing strength or time management.\n# Input samples: 'game_duration_seconds': [674.84, 492.27, 350.86], 'turn_number': [14.0, 14.0, 14.0]\ndf[\"avg_time_per_turn\"] = df[\"game_duration_seconds\"] / df[\"turn_number\"]\n\n# (avg_points_per_second: Average points scored per second)\n# Usefulness: Directly relates points output to time spent, which can reflect skill and efficiency.\n# Input samples: 'score': [429, 440, 119], 'game_duration_seconds': [674.84, 492.27, 350.86]\ndf[\"avg_points_per_second\"] = df[\"score\"] / df[\"game_duration_seconds\"]\n\n# (is_rated_game: 1 if rating_mode is RATED, else 0)\n# Usefulness: Indicates whether the game affects rating, which may affect player focus and effort.\n# Input samples: 'rating_mode': ['CASUAL', 'RATED', 'CASUAL']\ndf[\"is_rated_game\"] = (df[\"rating_mode\"] == \"RATED\").astype(int)\n\n# (is_standard_end: 1 if game_end_reason is STANDARD, else 0)\n# Usefulness: Separates standard finishes from resignations/timeouts, which may impact rating relevance.\n# Input samples: 'game_end_reason': ['STANDARD', 'STANDARD', 'RESIGNED']\ndf[\"is_standard_end\"] = (df[\"game_end_reason\"] == \"STANDARD\").astype(int)\n\n# (is_regular_time_control: 1 if time_control_name is 'regular', else 0)\n# Usefulness: Distinguishes standard controls from others (e.g. blitz), relevant for rating or skill inference.\n# Input samples: 'time_control_name': ['regular', 'regular', 'regular']\ndf[\"is_regular_time_control\"] = (df[\"time_control_name\"] == \"regular\").astype(int)\n\n# (score_per_turn: Average score per turn)\n# Usefulness: Proxy for move quality; more points per turn may indicate stronger player.\n# Input samples: 'score': [429, 440, 119], 'turn_number': [14.0, 14.0, 14.0]\ndf[\"score_per_turn\"] = df[\"score\"] / df[\"turn_number\"]\n\n# (turns_per_minute: Turns played per minute)\n# Usefulness: Indicates pace and possibly experience; faster turn rates can be correlated with skill/confidence.\n# Input samples: 'turn_number': [14.0, 14.0, 14.0], 'game_duration_seconds': [674.84, 492.27, 350.86]\ndf[\"turns_per_minute\"] = df[\"turn_number\"] / (df[\"game_duration_seconds\"] / 60.0)\n\n# (score_vs_expected: Score minus mean_score)\n# Usefulness: Measures performance above or below player's average; can indicate streaks or outliers which may affect rating volatility.\n# Input samples: 'score': [429, 440, 119], 'mean_score': [365.1, 348.17, 393.47]\ndf[\"score_vs_expected\"] = df[\"score\"] - df[\"mean_score\"]\n\n# (relative_score_diff: Score difference as a ratio of both players' total points)\n# Usefulness: Normalizes margin of victory for different scoring environments, yielding generalizable indicator.\n# Input samples: 'score_diff': [94, 122, -359], 'score': [429, 440, 119], 'other_mean_score': [393.38, 393.38, 393.38]\ndf[\"relative_score_diff\"] = df[\"score_diff\"] / (df[\"score\"] + df[\"other_mean_score\"]).replace(0, np.nan)\n\n# (early_finish: 1 if game completed in less than 60% of initial time)\n# Usefulness: Fast finishes may indicate resignations, blowouts, or confident play.\n# Input samples: 'game_duration_seconds': [674.84, 492.27, 350.86], 'initial_time_seconds': [1200, 900, 3600]\ndf[\"early_finish\"] = (df[\"game_duration_seconds\"] < 0.6 * df[\"initial_time_seconds\"]).astype(int)\n\n# (overtime_used_ratio: Ratio of overtime minutes used to allowed overtime)\n# Usefulness: High values may indicate time pressure, perhaps affecting play and outcomes.\n# Input samples: 'game_duration_seconds': [674.84, 492.27, 350.86], 'initial_time_seconds': [1200, 900, 3600], 'max_overtime_minutes': [1, 5, 1]\ndf[\"overtime_used_ratio\"] = (np.maximum(df[\"game_duration_seconds\"] - df[\"initial_time_seconds\"], 0) / (df[\"max_overtime_minutes\"] * 60)).replace([np.inf, -np.inf], 0).fillna(0)\n\n# (negative_score_diff: 1 if player lost, 0 if won/tied)\n# Usefulness: Binary indicator of loss, capturing the psychological/competitive aspect which can impact ratings.\n# Input samples: 'score_diff': [94, 122, -359]\ndf[\"negative_score_diff\"] = (df[\"score_diff\"] < 0).astype(int)\n\n# (points_mean_missing: 1 if points_mean is missing, else 0)\n# Usefulness: Explicitly flags missing values for model; missingness may carry predictive information.\n# Input samples: 'points_mean': [np.nan, np.nan, np.nan]\ndf[\"points_mean_missing\"] = df[\"points_mean\"].isna().astype(int)\n\n# (is_csw21_lexicon: 1 if lexicon is 'CSW21', else 0)\n# Usefulness: Different lexicons may be associated with different player pools/skill levels.\n# Input samples: 'lexicon': ['NWL20', 'CSW21', 'CSW21']\ndf[\"is_csw21_lexicon\"] = (df[\"lexicon\"] == \"CSW21\").astype(int)\n\n# (score_vs_other_mean: Score minus average opponent mean score)\n# Usefulness: Measures game performance relative to typical opponent level, adding context to \"raw\" score.\n# Input samples: 'score': [429, 440, 119], 'other_mean_score': [393.38, 393.38, 393.38]\ndf[\"score_vs_other_mean\"] = df[\"score\"] - df[\"other_mean_score\"]\n\n# (score_proportion: Score as proportion of total points scored in game)\n# Usefulness: Normalizes scoring performance, especially useful in high/low scoring games for rating differentiation.\n# Input samples: 'score': [429, 440, 119], 'score_diff': [94, 122, -359]\ndf[\"score_proportion\"] = (df[\"score\"] + np.maximum(df[\"score_diff\"], 0)) / (2 * df[\"score\"] + np.abs(df[\"score_diff\"]))\n# (points_mean_imputed: points_mean with missing values filled with mean of other available values)\n# Usefulness: Reduces missing data bias and provides a proxy for average points per turn in absence of direct observation.\n# Input samples: 'points_mean': [np.nan, np.nan, np.nan]\npoints_mean_mean = df[\"points_mean\"].mean(skipna=True)\ndf[\"points_mean_imputed\"] = df[\"points_mean\"].fillna(points_mean_mean)\n\n# (score_pct_of_mean: Player's score as percent of their mean_score)\n# Usefulness: Measures player performance deviation from historical norm, helpful for detecting streaks or slumps.\n# Input samples: 'score': [429, 440, 119], 'mean_score': [365.1, 348.17, 393.47]\ndf[\"score_pct_of_mean\"] = df[\"score\"] / df[\"mean_score\"]\n\n# (points_per_turn: points_mean divided by turn_number, with NaN protection)\n# Usefulness: Normalizes average points over turns; helps when points_mean is available.\n# Input samples: 'points_mean': [np.nan, np.nan, np.nan], 'turn_number': [14.0, 14.0, 14.0]\ndf[\"points_per_turn\"] = df[\"points_mean\"].fillna(0) / df[\"turn_number\"].replace(0, np.nan)\n\n# (score_advantage_ratio: Ratio of score_diff to player's score)\n# Usefulness: Highlights magnitude of player's win/loss in context of their total score.\n# Input samples: 'score_diff': [94, 122, -359], 'score': [429, 440, 119]\ndf[\"score_advantage_ratio\"] = df[\"score_diff\"] / df[\"score\"].replace(0, np.nan)\n\n# (is_first_player: Whether the player started the game)\n# Usefulness: Opening advantage can be significant in Scrabble; may correlate with rating.\n# Input samples: 'first_num': [0, 0, 0]\ndf[\"is_first_player\"] = df[\"first_num\"]\n\n# (average_move_length_per_game: len_move per turn)\n# Usefulness: May reflect play style or game openness, potentially correlated with player type/skill.\n# Input samples: 'len_move': [3.86, 4.36, 2.93], 'turn_number': [14.0, 14.0, 14.0]\ndf[\"average_move_length_per_game\"] = df[\"len_move\"] / df[\"turn_number\"].replace(0, np.nan)\n\n# (score_deficit: Negative of score_diff; 0 if player won)\n# Usefulness: Focuses on loss margin; outsized losses may impact future rating estimates.\n# Input samples: 'score_diff': [94, 122, -359]\ndf[\"score_deficit\"] = np.where(df[\"score_diff\"] < 0, -df[\"score_diff\"], 0)\n\n# (has_overtime: 1 if max_overtime_minutes > 1, else 0)\n# Usefulness: Longer overtime can indicate different pacing/pressure; may select for more competitive games.\n# Input samples: 'max_overtime_minutes': [1, 5, 1]\ndf[\"has_overtime\"] = (df[\"max_overtime_minutes\"] > 1).astype(int)\n\n# (score_opponent_ratio: Player score divided by (player score + opponent mean score))\n# Usefulness: Normalizes performance against expectation set by opponent's average level.\n# Input samples: 'score': [429, 440, 119], 'other_mean_score': [393.38, 393.38, 393.38]\ndf[\"score_opponent_ratio\"] = df[\"score\"] / (df[\"score\"] + df[\"other_mean_score\"])\n\n# (time_per_point: Seconds per point scored)\n# Usefulness: Inverse of points per second; slow, methodical play may indicate higher skill.\n# Input samples: 'game_duration_seconds': [674.84, 492.27, 350.86], 'score': [429, 440, 119]\ndf[\"time_per_point\"] = df[\"game_duration_seconds\"] / df[\"score\"].replace(0, np.nan)\n\n# (is_nwl20_lexicon: 1 if lexicon is NWL20, else 0)\n# Usefulness: Lexicon can signal regional play or distinct communities, useful for rating context.\n# Input samples: 'lexicon': ['NWL20', 'CSW21', 'CSW21']\ndf[\"is_nwl20_lexicon\"] = (df[\"lexicon\"] == \"NWL20\").astype(int)\n\n# (is_casual_game: 1 if rating_mode is CASUAL, else 0)\n# Usefulness: Opposite of is_rated_game; helpful for model to distinguish game contexts explicitly.\n# Input samples: 'rating_mode': ['CASUAL', 'RATED', 'CASUAL']\ndf[\"is_casual_game\"] = (df[\"rating_mode\"] == \"CASUAL\").astype(int)\n\n# (is_ecwl_lexicon: 1 if lexicon is ECWL, else 0)\n# Usefulness: Adds additional lexicon signal; player pool may be distinct.\n# Input samples: 'lexicon': ['NWL20', 'CSW21', 'CSW21']\ndf[\"is_ecwl_lexicon\"] = (df[\"lexicon\"] == \"ECWL\").astype(int)\n\n# (large_win: 1 if score_diff > 100, else 0)\n# Usefulness: Winning by a large margin may reflect skill gap, correlating to higher rating.\n# Input samples: 'score_diff': [94, 122, -359]\ndf[\"large_win\"] = (df[\"score_diff\"] > 100).astype(int)\n\n# (game_duration_minutes: Game duration in minutes)\n# Usefulness: Normalizes time features and may be easier for the model to interpret than seconds.\n# Input samples: 'game_duration_seconds': [674.84, 492.27, 350.86]\ndf[\"game_duration_minutes\"] = df[\"game_duration_seconds\"] / 60.0\n# (score_normalized: z-score of player's score across dataset)\n# Usefulness: Identifies outlier games, contextualizing player's performance relative to population.\n# Input samples: 'score': [429, 440, 119]\ndf[\"score_normalized\"] = (df[\"score\"] - df[\"score\"].mean()) / df[\"score\"].std(ddof=0)\n\n# (mean_score_normalized: z-score of mean_score across dataset)\n# Usefulness: Captures whether player is generally above/below average, which may be predictive of rating.\n# Input samples: 'mean_score': [365.1, 348.17, 393.47]\ndf[\"mean_score_normalized\"] = (df[\"mean_score\"] - df[\"mean_score\"].mean()) / df[\"mean_score\"].std(ddof=0)\n\n# (duration_pct_of_initial: Duration of game as percentage of initial allotted time)\n# Usefulness: Indicates how much of the allotted time is typically used by the player.\n# Input samples: 'game_duration_seconds': [674.84, 492.27, 350.86], 'initial_time_seconds': [1200, 900, 3600]\ndf[\"duration_pct_of_initial\"] = df[\"game_duration_seconds\"] / df[\"initial_time_seconds\"]\n\n# (turn_number_normalized: z-score of turn_number)\n# Usefulness: Adjusts for games of varying length, allowing model to see unusual turn counts.\n# Input samples: 'turn_number': [14.0, 14.0, 14.0]\ndf[\"turn_number_normalized\"] = (df[\"turn_number\"] - df[\"turn_number\"].mean()) / df[\"turn_number\"].std(ddof=0)\n\n# (move_length_normalized: z-score of len_move)\n# Usefulness: Highlights players or games with unusually short/long average moves, which may be skill dependent.\n# Input samples: 'len_move': [3.86, 4.36, 2.93]\ndf[\"move_length_normalized\"] = (df[\"len_move\"] - df[\"len_move\"].mean()) / df[\"len_move\"].std(ddof=0)\n\n# (max_overtime_flag: 1 if max_overtime_minutes is max in dataset, else 0)\n# Usefulness: Unusual overtime settings may affect game dynamics and ratings.\n# Input samples: 'max_overtime_minutes': [1, 5, 1]\ndf[\"max_overtime_flag\"] = (df[\"max_overtime_minutes\"] == df[\"max_overtime_minutes\"].max()).astype(int)\n\n# (score_diff_abs: Absolute value of score_diff)\n# Usefulness: Encodes margin of victory/loss regardless of winner, always meaningful for rating.\n# Input samples: 'score_diff': [94, 122, -359]\ndf[\"score_diff_abs\"] = df[\"score_diff\"].abs()\n\n# (above_average_score: 1 if score above mean_score, else 0)\n# Usefulness: Binary performance flag for in-game over/under-performance.\n# Input samples: 'score': [429, 440, 119], 'mean_score': [365.1, 348.17, 393.47]\ndf[\"above_average_score\"] = (df[\"score\"] > df[\"mean_score\"]).astype(int)\n\n# (lost_large: 1 if score_diff < -100, else 0)\n# Usefulness: Indicates outsized losses, which may correlate to volatility in rating.\n# Input samples: 'score_diff': [94, 122, -359]\ndf[\"lost_large\"] = (df[\"score_diff\"] < -100).astype(int)\n\n# (game_end_not_standard: 1 if game_end_reason != STANDARD, else 0)\n# Usefulness: Provides explicit flag for non-standard finishes, which may affect rating differently.\n# Input samples: 'game_end_reason': ['STANDARD', 'STANDARD', 'RESIGNED']\ndf[\"game_end_not_standard\"] = (df[\"game_end_reason\"] != \"STANDARD\").astype(int)\n\n# (score_vs_diffmean: Score minus diff_mean_score)\n# Usefulness: Magnifies games where player greatly over/underperformed relative to both their and their opponent's averages.\n# Input samples: 'score': [429, 440, 119], 'diff_mean_score': [-28.27, -45.21, 0.1]\ndf[\"score_vs_diffmean\"] = df[\"score\"] - df[\"diff_mean_score\"]\n\n# (score_diff_sign: -1 for loss, 0 for draw, 1 for win)\n# Usefulness: Encodes win/loss/tie information for simpler modeling.\n# Input samples: 'score_diff': [94, 122, -359]\ndf[\"score_diff_sign\"] = np.sign(df[\"score_diff\"]).astype(int)\n\n# (casual_standard_combined: 1 if game is both CASUAL and STANDARD, else 0)\n# Usefulness: Identifies non-competitive but standard finish games for special treatment.\n# Input samples: 'rating_mode': ['CASUAL', 'RATED', 'CASUAL'], 'game_end_reason': ['STANDARD', 'STANDARD', 'RESIGNED']\ndf[\"casual_standard_combined\"] = ((df[\"rating_mode\"] == \"CASUAL\") & (df[\"game_end_reason\"] == \"STANDARD\")).astype(int)\n\n# (score_turnratio: Score divided by (turn_number*100), normalizes for length of game)\n# Usefulness: Helps compare scoring output over different game lengths.\n# Input samples: 'score': [429, 440, 119], 'turn_number': [14.0, 14.0, 14.0]\ndf[\"score_turnratio\"] = df[\"score\"] / (df[\"turn_number\"] * 100)\n\n# (turns_vs_expected: Turn number minus dataset mean)\n# Usefulness: Captures deviation from typical game length.\n# Input samples: 'turn_number': [14.0, 14.0, 14.0]\ndf[\"turns_vs_expected\"] = df[\"turn_number\"] - df[\"turn_number\"].mean()\n# (other_mean_score_normalized: z-score of other_mean_score)\n# Usefulness: Contextualizes opponent's average strength, aiding model's understanding of game context.\n# Input samples: 'other_mean_score': [393.38, 393.38, 393.38]\ndf[\"other_mean_score_normalized\"] = (df[\"other_mean_score\"] - df[\"other_mean_score\"].mean()) / df[\"other_mean_score\"].std(ddof=0)\n\n# (diff_mean_score_normalized: z-score of diff_mean_score)\n# Usefulness: Normalizes player's advantage/disadvantage for comparability across dataset.\n# Input samples: 'diff_mean_score': [-28.27, -45.21, 0.1]\ndf[\"diff_mean_score_normalized\"] = (df[\"diff_mean_score\"] - df[\"diff_mean_score\"].mean()) / df[\"diff_mean_score\"].std(ddof=0)\n\n# (turns_to_duration_ratio: Ratio of turns to game duration)\n# Usefulness: Captures granularity of play, may distinguish fast/slow or high/low scoring styles.\n# Input samples: 'turn_number': [14.0, 14.0, 14.0], 'game_duration_seconds': [674.84, 492.27, 350.86]\ndf[\"turns_to_duration_ratio\"] = df[\"turn_number\"] / df[\"game_duration_seconds\"].replace(0, np.nan)\n\n# (score_efficiency: Score divided by duration_pct_of_initial)\n# Usefulness: Measures scoring speed relative to time used; high values could flag efficient players.\n# Input samples: 'score': [429, 440, 119], 'duration_pct_of_initial': [0.562, 0.547, 0.097]\ndf[\"score_efficiency\"] = df[\"score\"] / df[\"duration_pct_of_initial\"].replace(0, np.nan)\n\n# (turn_density: Turns per minute of initial time)\n# Usefulness: Captures intended game pace by settings, independent of actual play.\n# Input samples: 'turn_number': [14.0, 14.0, 14.0], 'initial_time_seconds': [1200, 900, 3600]\ndf[\"turn_density\"] = df[\"turn_number\"] / (df[\"initial_time_seconds\"] / 60)\n\n# (score_minmax_scaled: Score min-max scaled to [0,1])\n# Usefulness: Provides normalized score for tree-based models.\n# Input samples: 'score': [429, 440, 119]\nscore_min = df[\"score\"].min()\nscore_max = df[\"score\"].max()\ndf[\"score_minmax_scaled\"] = (df[\"score\"] - score_min) / (score_max - score_min)\n\n# (score_diff_over_mean: Score difference over mean_score)\n# Usefulness: Flags outlier performances considering player's average.\n# Input samples: 'score_diff': [94, 122, -359], 'mean_score': [365.1, 348.17, 393.47]\ndf[\"score_diff_over_mean\"] = df[\"score_diff\"] / df[\"mean_score\"].replace(0, np.nan)\n\n# (game_short: 1 if number of turns fewer than median, else 0)\n# Usefulness: Binary flag for short games, may indicate resignations or high efficiency.\n# Input samples: 'turn_number': [14.0, 14.0, 14.0]\ndf[\"game_short\"] = (df[\"turn_number\"] < df[\"turn_number\"].median()).astype(int)\n\n# (move_length_high: 1 if len_move above 75th percentile, else 0)\n# Usefulness: Identifies unusually long moves, which could signal skill or desperation.\n# Input samples: 'len_move': [3.86, 4.36, 2.93]\nmove_length_75 = df[\"len_move\"].quantile(0.75)\ndf[\"move_length_high\"] = (df[\"len_move\"] > move_length_75).astype(int)\n\n# (time_exceeded: 1 if game_duration_seconds > initial_time_seconds, else 0)\n# Usefulness: Flags games where overtime was triggered.\n# Input samples: 'game_duration_seconds': [674.84, 492.27, 350.86], 'initial_time_seconds': [1200, 900, 3600]\ndf[\"time_exceeded\"] = (df[\"game_duration_seconds\"] > df[\"initial_time_seconds\"]).astype(int)\n\n# (is_regular_and_standard: 1 if both time_control_name is regular and game_end_reason is STANDARD)\n# Usefulness: Explicitly encodes standard/regular competitive conditions.\n# Input samples: 'time_control_name': ['regular', 'regular', 'regular'], 'game_end_reason': ['STANDARD', 'STANDARD', 'RESIGNED']\ndf[\"is_regular_and_standard\"] = ((df[\"time_control_name\"] == \"regular\") & (df[\"game_end_reason\"] == \"STANDARD\")).astype(int)\n\n# (score_vs_points_min: Player's score minus points_min, fillna for missing points_min)\n# Usefulness: Measures how much player exceeded their lowest scoring play, indicating consistency.\n# Input samples: 'score': [429, 440, 119], 'points_min': [np.nan, np.nan, np.nan]\ndf[\"score_vs_points_min\"] = df[\"score\"] - df.get(\"points_min\", pd.Series(np.nan, index=df.index)).fillna(0)\n\n# (has_max_overtime: 1 if max_overtime_minutes equals 10, else 0)\n# Usefulness: Flag for games with very high overtime allowance, different dynamics.\n# Input samples: 'max_overtime_minutes': [1, 5, 1]\ndf[\"has_max_overtime\"] = (df[\"max_overtime_minutes\"] == 10).astype(int)\n\n# (score_per_minute: Score per minute of actual duration)\n# Usefulness: Alternative efficiency metric to avg_points_per_second, may be more interpretable.\n# Input samples: 'score': [429, 440, 119], 'game_duration_seconds': [674.84, 492.27, 350.86]\ndf[\"score_per_minute\"] = df[\"score\"] / (df[\"game_duration_seconds\"] / 60)\n\n# (score_diff_pct_total: Score_diff as percent of total points in game)\n# Usefulness: Normalizes win margin for modeling, regardless of absolute score scale.\n# Input samples: 'score_diff': [94, 122, -359], 'score': [429, 440, 119], 'other_mean_score': [393.38, 393.38, 393.38]\ndf[\"score_diff_pct_total\"] = df[\"score_diff\"] / (df[\"score\"] + df[\"other_mean_score\"]).replace(0, np.nan) * 100\n\n# (move_length_vs_mean: Difference between len_move and its dataset mean)\n# Usefulness: Flags unusually long or short average moves.\n# Input samples: 'len_move': [3.86, 4.36, 2.93]\ndf[\"move_length_vs_mean\"] = df[\"len_move\"] - df[\"len_move\"].mean()\n# (score_vs_points_max: Player's score minus points_max, fillna for missing points_max)\n# Usefulness: Measures how much player exceeded their highest single play, a proxy for consistency.\n# Input samples: 'score': [429, 440, 119], 'points_max': [np.nan, np.nan, np.nan]\ndf[\"score_vs_points_max\"] = df[\"score\"] - df.get(\"points_max\", pd.Series(np.nan, index=df.index)).fillna(0)\n\n# (points_max_minus_min: Difference between points_max and points_min, fillna protection)\n# Usefulness: Captures range in player performance in a game, indicative of volatility.\n# Input samples: 'points_max': [np.nan, np.nan, np.nan], 'points_min': [np.nan, np.nan, np.nan]\ndf[\"points_max_minus_min\"] = df.get(\"points_max\", pd.Series(np.nan, index=df.index)).fillna(0) - df.get(\"points_min\", pd.Series(np.nan, index=df.index)).fillna(0)\n\n# (score_vs_points_mean: Player's score minus points_mean, fillna for missing points_mean)\n# Usefulness: Provides a measure of overall performance above average play quality.\n# Input samples: 'score': [429, 440, 119], 'points_mean': [np.nan, np.nan, np.nan]\ndf[\"score_vs_points_mean\"] = df[\"score\"] - df[\"points_mean\"].fillna(0)\n\n# (log_score: Natural logarithm of score plus one)\n# Usefulness: Reduces skew, stabilizes variance for regression models, especially with long-tailed scores.\n# Input samples: 'score': [429, 440, 119]\ndf[\"log_score\"] = np.log1p(df[\"score\"])\n\n# (log_game_duration: Natural logarithm of game_duration_seconds plus one)\n# Usefulness: Reduces skew, stabilizes variance in game duration for downstream models.\n# Input samples: 'game_duration_seconds': [674.84, 492.27, 350.86]\ndf[\"log_game_duration\"] = np.log1p(df[\"game_duration_seconds\"])\n\n# (turns_over_duration_pct: Turns divided by duration_pct_of_initial)\n# Usefulness: Indicates turn density relative to expected game time, could correlate with playing style.\n# Input samples: 'turn_number': [14.0, 14.0, 14.0], 'duration_pct_of_initial': [0.562, 0.547, 0.097]\ndf[\"turns_over_duration_pct\"] = df[\"turn_number\"] / df[\"duration_pct_of_initial\"].replace(0, np.nan)\n\n# (is_fast_game: 1 if duration_pct_of_initial < 0.5, else 0)\n# Usefulness: Encodes games completed rapidly, potentially due to early resignation or dominant play.\n# Input samples: 'duration_pct_of_initial': [0.562, 0.547, 0.097]\ndf[\"is_fast_game\"] = (df[\"duration_pct_of_initial\"] < 0.5).astype(int)\n\n# (score_minus_score_diff: Player's score minus score_diff)\n# Usefulness: Estimates opponent's score for context, without using their actual value directly.\n# Input samples: 'score': [429, 440, 119], 'score_diff': [94, 122, -359]\ndf[\"score_minus_score_diff\"] = df[\"score\"] - df[\"score_diff\"]\n\n# (score_plus_score_diff: Player's score plus score_diff)\n# Usefulness: Sums to double the player\u2019s score if they won, else gives opponent\u2019s score, enabling quick comparisons.\n# Input samples: 'score': [429, 440, 119], 'score_diff': [94, 122, -359]\ndf[\"score_plus_score_diff\"] = df[\"score\"] + df[\"score_diff\"]\n\n# (score_diff_over_turns: Score difference per turn played)\n# Usefulness: Win/loss margin normalized by game length; can highlight close or blowout matches.\n# Input samples: 'score_diff': [94, 122, -359], 'turn_number': [14.0, 14.0, 14.0]\ndf[\"score_diff_over_turns\"] = df[\"score_diff\"] / df[\"turn_number\"].replace(0, np.nan)\n\n# (turn_number_over_mean: Turn number divided by dataset mean)\n# Usefulness: Normalizes number of turns for seasonality/variance in game length.\n# Input samples: 'turn_number': [14.0, 14.0, 14.0]\ndf[\"turn_number_over_mean\"] = df[\"turn_number\"] / df[\"turn_number\"].mean()\n\n# (score_over_other_mean: Player's score divided by opponent's mean score)\n# Usefulness: Encodes relative performance versus typical opponent output.\n# Input samples: 'score': [429, 440, 119], 'other_mean_score': [393.38, 393.38, 393.38]\ndf[\"score_over_other_mean\"] = df[\"score\"] / df[\"other_mean_score\"].replace(0, np.nan)\n\n# (score_vs_initial_time: Score divided by initial_time_seconds)\n# Usefulness: Measures points output relative to game configuration, useful for cross-control comparability.\n# Input samples: 'score': [429, 440, 119], 'initial_time_seconds': [1200, 900, 3600]\ndf[\"score_vs_initial_time\"] = df[\"score\"] / df[\"initial_time_seconds\"].replace(0, np.nan)\n\n# (is_nonstandard_lexicon: 1 if lexicon not in CSW21 or NWL20, else 0)\n# Usefulness: Flags unusual lexicons (e.g. ECWL), which may be associated with different player pools.\n# Input samples: 'lexicon': ['NWL20', 'CSW21', 'CSW21']\ndf[\"is_nonstandard_lexicon\"] = ~df[\"lexicon\"].isin([\"CSW21\", \"NWL20\"]).astype(int)\n\n# (score_diff_to_other_mean: Score difference divided by opponent mean score)\n# Usefulness: Scales win/loss magnitude by expected output of opponent.\n# Input samples: 'score_diff': [94, 122, -359], 'other_mean_score': [393.38, 393.38, 393.38]\ndf[\"score_diff_to_other_mean\"] = df[\"score_diff\"] / df[\"other_mean_score\"].replace(0, np.nan)\n# (score_plus_other_mean: Player's score plus opponent's mean score)\n# Usefulness: Sums offensive output and opponent's expected strength, giving context for the absolute score.\n# Input samples: 'score': [429, 440, 119], 'other_mean_score': [393.38, 393.38, 393.38]\ndf[\"score_plus_other_mean\"] = df[\"score\"] + df[\"other_mean_score\"]\n\n# (score_minus_other_mean: Player's score minus opponent's mean score)\n# Usefulness: Flags outlier victories or defeats relative to opponent\u2019s average level.\n# Input samples: 'score': [429, 440, 119], 'other_mean_score': [393.38, 393.38, 393.38]\ndf[\"score_minus_other_mean\"] = df[\"score\"] - df[\"other_mean_score\"]\n\n# (score_to_opponent_percent: Player's score as percent of opponent's mean score)\n# Usefulness: Offers relative performance per match.\n# Input samples: 'score': [429, 440, 119], 'other_mean_score': [393.38, 393.38, 393.38]\ndf[\"score_to_opponent_percent\"] = df[\"score\"] / df[\"other_mean_score\"].replace(0, np.nan) * 100\n\n# (score_diff_to_total_score: Proportion of score_diff to total score by both players)\n# Usefulness: Normalizes result margin, especially in high/low scoring games.\n# Input samples: 'score_diff': [94, 122, -359], 'score': [429, 440, 119], 'other_mean_score': [393.38, 393.38, 393.38]\ndf[\"score_diff_to_total_score\"] = df[\"score_diff\"] / (df[\"score\"] + df[\"other_mean_score\"]).replace(0, np.nan)\n\n# (turns_to_initial_time: Number of turns per minute of initial allotted time)\n# Usefulness: Encodes how quickly the player plays compared to what was available.\n# Input samples: 'turn_number': [14.0, 14.0, 14.0], 'initial_time_seconds': [1200, 900, 3600]\ndf[\"turns_to_initial_time\"] = df[\"turn_number\"] / (df[\"initial_time_seconds\"] / 60)\n\n# (mean_score_to_other_mean: Ratio of player's mean_score to opponent's mean score)\n# Usefulness: Puts player's overall level in direct relation to their likely competition.\n# Input samples: 'mean_score': [365.1, 348.17, 393.47], 'other_mean_score': [393.38, 393.38, 393.38]\ndf[\"mean_score_to_other_mean\"] = df[\"mean_score\"] / df[\"other_mean_score\"].replace(0, np.nan)\n\n# (score_variance_est: Proxy for variance: abs(score - mean_score))\n# Usefulness: Measures volatility of performance; higher variance may signal streaky or inconsistent players.\n# Input samples: 'score': [429, 440, 119], 'mean_score': [365.1, 348.17, 393.47]\ndf[\"score_variance_est\"] = (df[\"score\"] - df[\"mean_score\"]).abs()\n\n# (points_mean_over_score: Ratio of points_mean to total score, fillna)\n# Usefulness: Measures how much of scoring is due to average play, accounting for missing points_mean.\n# Input samples: 'points_mean': [np.nan, np.nan, np.nan], 'score': [429, 440, 119]\ndf[\"points_mean_over_score\"] = df[\"points_mean\"].fillna(0) / df[\"score\"].replace(0, np.nan)\n\n# (score_times_turns: Product of score and turn_number)\n# Usefulness: Encodes high-scoring, long games; can flag both volume and consistent performance.\n# Input samples: 'score': [429, 440, 119], 'turn_number': [14.0, 14.0, 14.0]\ndf[\"score_times_turns\"] = df[\"score\"] * df[\"turn_number\"]\n\n# (mean_score_diff_sign: Sign of diff_mean_score; 1 if player better than opponent average, -1 if worse, 0 if equal)\n# Usefulness: Binary indicator for direction of average-performance advantage.\n# Input samples: 'diff_mean_score': [-28.27, -45.21, 0.1]\ndf[\"mean_score_diff_sign\"] = np.sign(df[\"diff_mean_score\"]).astype(int)\n\n# (points_mean_nonzero: 1 if points_mean is not NaN and > 0, else 0)\n# Usefulness: Flags games with valid, non-zero points_mean for downstream model.\n# Input samples: 'points_mean': [np.nan, np.nan, np.nan]\ndf[\"points_mean_nonzero\"] = ((~df[\"points_mean\"].isna()) & (df[\"points_mean\"] > 0)).astype(int)\n\n# (is_overtime_game: 1 if game_duration_seconds > initial_time_seconds, else 0)\n# Usefulness: Explicit indicator for games that required overtime.\n# Input samples: 'game_duration_seconds': [674.84, 492.27, 350.86], 'initial_time_seconds': [1200, 900, 3600]\ndf[\"is_overtime_game\"] = (df[\"game_duration_seconds\"] > df[\"initial_time_seconds\"]).astype(int)\n\n# (score_diff_times_turns: Product of score_diff and turn_number)\n# Usefulness: Joint indicator of win/loss magnitude and game length.\n# Input samples: 'score_diff': [94, 122, -359], 'turn_number': [14.0, 14.0, 14.0]\ndf[\"score_diff_times_turns\"] = df[\"score_diff\"] * df[\"turn_number\"]\n\n# (score_minus_mean_score: Player's score minus their mean score)\n# Usefulness: Direct performance deviation from expectation.\n# Input samples: 'score': [429, 440, 119], 'mean_score': [365.1, 348.17, 393.47]\ndf[\"score_minus_mean_score\"] = df[\"score\"] - df[\"mean_score\"]\n\n# (turn_number_times_win: Product of turn_number and Win indicator)\n# Usefulness: Encodes relationship between game length and winning; may be different for strong vs. weak players.\n# Input samples: 'turn_number': [14.0, 14.0, 14.0], 'Win': [1, 1, 0]\ndf[\"turn_number_times_win\"] = df[\"turn_number\"] * df[\"Win\"]\n"
    ]
}